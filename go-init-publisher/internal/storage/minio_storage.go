package storage

import (
	"context"
	"fmt"
	"io"
	"net/url"
	"time"

	"github.com/google/uuid"
	"github.com/minio/minio-go/v7"
	common "gitlab.com/go-init/go-init-common/default/kafka"
	"gitlab.com/go-init/go-init-common/default/logger"
	minio_client "gitlab.com/go-init/go-init-common/default/s3/minio"
)

const (
	// ContentTypeZip - MIME —Ç–∏–ø –¥–ª—è ZIP-–∞—Ä—Ö–∏–≤–æ–≤
	ContentTypeZip = "application/zip"

	// FileExtensionZip - —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ ZIP-–∞—Ä—Ö–∏–≤–∞
	FileExtensionZip = ".zip"

	// EventTypeArchiveReady - —Ç–∏–ø —Å–æ–±—ã—Ç–∏—è –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –∞—Ä—Ö–∏–≤–∞
	EventTypeArchiveReady = "archive-ready"

	// EventSchemaArchive - —Å—Ö–µ–º–∞ —Å–æ–±—ã—Ç–∏—è –∞—Ä—Ö–∏–≤–∞
	EventSchemaArchive = "go-init-archive-schema"

	// EventSourcePublisher - –∏—Å—Ç–æ—á–Ω–∏–∫ —Å–æ–±—ã—Ç–∏—è
	EventSourcePublisher = "go-init-publisher"

	// PresignedURLExpiry - —Å—Ä–æ–∫ –¥–µ–π—Å—Ç–≤–∏—è –ø—Ä–µ—Å–∏–≥–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å—Å—ã–ª–∫–∏ (24 —á–∞—Å–∞)
	PresignedURLExpiry = 24 * time.Hour
)

// MinIOStorage —Ä–µ–∞–ª–∏–∑—É–µ—Ç –æ–ø–µ—Ä–∞—Ü–∏–∏ —Ö—Ä–∞–Ω–µ–Ω–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º MinIO
type MinIOStorage struct {
	minioClient   *minio_client.Client
	kafkaProducer *common.ClientConfig
	log           *logger.Logger
	config        *minio_client.Config
	topic         string
}

// NewMinIOStorage —Å–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ MinIO
func NewMinIOStorage(minioClient *minio_client.Client, kafkaProducer *common.ClientConfig, log *logger.Logger, config *minio_client.Config, topic string) *MinIOStorage {
	return &MinIOStorage{
		minioClient:   minioClient,
		kafkaProducer: kafkaProducer,
		log:           log,
		config:        config,
		topic:         topic,
	}
}

// SaveArchive —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∞—Ä—Ö–∏–≤ –≤ MinIO –∏ –ø—É–±–ª–∏–∫—É–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤ Kafka
func (s *MinIOStorage) SaveArchive(ctx context.Context, archiveID string, data []byte) (string, error) {
	// –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –∞—Ä—Ö–∏–≤–∞
	if archiveID == "" {
		archiveID = uuid.New().String()
		s.log.WarnContext(ctx, "–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω –ø—É—Å—Ç–æ–π ID –∞—Ä—Ö–∏–≤–∞, —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –Ω–æ–≤—ã–π",
			logger.String("archive_id", archiveID))
	}

	// –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–º–µ–Ω–∏ –æ–±—ä–µ–∫—Ç–∞
	objectName := fmt.Sprintf("%s%s", archiveID, FileExtensionZip)

	// –ó–∞–≥—Ä—É–∑–∫–∞ –∞—Ä—Ö–∏–≤–∞ –≤ MinIO
	s.log.InfoContext(ctx, "–ó–∞–≥—Ä—É–∑–∫–∞ –∞—Ä—Ö–∏–≤–∞ –≤ MinIO",
		logger.String("object_name", objectName),
		logger.String("bucket", s.config.DefaultBucket))

	info, err := s.minioClient.UploadObject(ctx, s.config.DefaultBucket, objectName, data, ContentTypeZip)
	if err != nil {
		s.log.ErrorContext(ctx, "–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∞—Ä—Ö–∏–≤–∞ –≤ MinIO",
			logger.String("object_name", objectName),
			logger.Error(err))
		return "", fmt.Errorf("–æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∞—Ä—Ö–∏–≤–∞ –≤ MinIO: %w", err)
	}

	// –°–æ–∑–¥–∞–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
	archiveMetadata := s.createArchiveMetadata(ctx, info, archiveID, objectName)

	// –ü—É–±–ª–∏–∫–∞—Ü–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤ Kafka
	s.publishMetadataToKafka(ctx, archiveMetadata, objectName)

	return objectName, nil
}

// SaveArchiveFromReader —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∞—Ä—Ö–∏–≤ –∏–∑ –ø–æ—Ç–æ–∫–∞ –≤ MinIO –∏ –ø—É–±–ª–∏–∫—É–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤ Kafka
func (s *MinIOStorage) SaveArchiveFromReader(ctx context.Context, reader io.Reader, size int64) (string, error) {
	// –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ ID –¥–ª—è –∞—Ä—Ö–∏–≤–∞
	archiveID := uuid.New().String()
	objectName := fmt.Sprintf("%s%s", archiveID, FileExtensionZip)

	// –ó–∞–≥—Ä—É–∑–∫–∞ –∞—Ä—Ö–∏–≤–∞ –≤ MinIO –∏–∑ –ø–æ—Ç–æ–∫–∞
	s.log.InfoContext(ctx, "–ó–∞–≥—Ä—É–∑–∫–∞ –∞—Ä—Ö–∏–≤–∞ –≤ MinIO –∏–∑ –ø–æ—Ç–æ–∫–∞",
		logger.String("object_name", objectName),
		logger.String("bucket", s.config.DefaultBucket),
		logger.Int64("size", size))

	info, err := s.minioClient.UploadObjectFromReader(ctx, s.config.DefaultBucket, objectName, reader, size, ContentTypeZip)
	if err != nil {
		s.log.ErrorContext(ctx, "–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∞—Ä—Ö–∏–≤–∞ –≤ MinIO –∏–∑ –ø–æ—Ç–æ–∫–∞",
			logger.String("object_name", objectName),
			logger.Error(err))
		return "", fmt.Errorf("–æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∞—Ä—Ö–∏–≤–∞ –≤ MinIO –∏–∑ –ø–æ—Ç–æ–∫–∞: %w", err)
	}

	// –°–æ–∑–¥–∞–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
	archiveMetadata := s.createArchiveMetadata(ctx, info, archiveID, objectName)

	// –ü—É–±–ª–∏–∫–∞—Ü–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤ Kafka
	s.publishMetadataToKafka(ctx, archiveMetadata, objectName)

	return objectName, nil
}

// createArchiveMetadata —Å–æ–∑–¥–∞–µ—Ç –∏ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∞—Ä—Ö–∏–≤–∞
func (s *MinIOStorage) createArchiveMetadata(ctx context.Context, info minio.UploadInfo, archiveID string, objectName string) *minio_client.ArchiveMetadata {
	// –°–æ–∑–¥–∞–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–∞
	objectMetadata := minio_client.NewObjectMetadata(
		info.Bucket,
		objectName,
		info.Size,
		ContentTypeZip,
		info.ETag,
	)

	// –°–æ–∑–¥–∞–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∞—Ä—Ö–∏–≤–∞
	archiveMetadata := minio_client.NewArchiveMetadata(objectMetadata, "zip")
	archiveMetadata.ID = archiveID

	// –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–µ—Å–∏–≥–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å—Å—ã–ª–∫–∏
	presignedURL, err := s.GeneratePresignedURL(ctx, objectName, PresignedURLExpiry)
	if err != nil {
		s.log.WarnContext(ctx, "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–µ—Å–∏–≥–Ω–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å—Å—ã–ª–∫—É",
			logger.String("object_name", objectName),
			logger.Error(err))
	} else {
		archiveMetadata.SetPresignedURL(presignedURL, PresignedURLExpiry)
	}

	return &archiveMetadata
}

// publishMetadataToKafka –ø—É–±–ª–∏–∫—É–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∞—Ä—Ö–∏–≤–∞ –≤ Kafka
func (s *MinIOStorage) publishMetadataToKafka(ctx context.Context, metadata *minio_client.ArchiveMetadata, objectName string) {
	// –ü—É–±–ª–∏–∫–∞—Ü–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤ Kafka, –µ—Å–ª–∏ –ø—Ä–æ–¥—é—Å–µ—Ä –≤–∫–ª—é—á–µ–Ω
	if s.kafkaProducer.IsEnabled() {
		s.log.InfoContext(ctx, "–ü—É–±–ª–∏–∫–∞—Ü–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∞—Ä—Ö–∏–≤–∞ –≤ Kafka",
			logger.String("topic", s.topic),
			logger.String("archive_id", metadata.ID))

		event := &common.ProduceEvent{
			Type:    EventTypeArchiveReady,
			Schema:  EventSchemaArchive,
			Source:  EventSourcePublisher,
			TopicID: s.topic,
		}

		event.SetCorrelationID(uuid.New().String())
		event.SetData(metadata)

		s.kafkaProducer.Produce(ctx, event)
		s.log.InfoContext(ctx, "–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∞—Ä—Ö–∏–≤–∞ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω—ã –≤ Kafka",
			logger.String("object_name", objectName))
	} else {
		s.log.InfoContext(ctx, "Kafka –ø—Ä–æ–¥—é—Å–µ—Ä –æ—Ç–∫–ª—é—á–µ–Ω, –ø—Ä–æ–ø—É—Å–∫ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö")
	}
}

// DownloadArchive –∑–∞–≥—Ä—É–∂–∞–µ—Ç –∞—Ä—Ö–∏–≤ –∏–∑ MinIO
func (s *MinIOStorage) DownloadArchive(ctx context.Context, objectName string) ([]byte, error) {
	s.log.InfoContext(ctx, "–ó–∞–≥—Ä—É–∑–∫–∞ –∞—Ä—Ö–∏–≤–∞ –∏–∑ MinIO",
		logger.String("object_name", objectName),
		logger.String("bucket", s.config.DefaultBucket))

	data, err := s.minioClient.DownloadObject(ctx, s.config.DefaultBucket, objectName)
	if err != nil {
		s.log.ErrorContext(ctx, "–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∞—Ä—Ö–∏–≤–∞ –∏–∑ MinIO",
			logger.String("object_name", objectName),
			logger.Error(err))
		return nil, fmt.Errorf("–æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∞—Ä—Ö–∏–≤–∞ –∏–∑ MinIO: %w", err)
	}

	return data, nil
}

// DeleteArchive —É–¥–∞–ª—è–µ—Ç –∞—Ä—Ö–∏–≤ –∏–∑ MinIO
func (s *MinIOStorage) DeleteArchive(ctx context.Context, objectName string) error {
	s.log.InfoContext(ctx, "–£–¥–∞–ª–µ–Ω–∏–µ –∞—Ä—Ö–∏–≤–∞ –∏–∑ MinIO",
		logger.String("object_name", objectName),
		logger.String("bucket", s.config.DefaultBucket))

	err := s.minioClient.DeleteObject(ctx, s.config.DefaultBucket, objectName)
	if err != nil {
		s.log.ErrorContext(ctx, "–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –∞—Ä—Ö–∏–≤–∞ –∏–∑ MinIO",
			logger.String("object_name", objectName),
			logger.Error(err))
		return fmt.Errorf("–æ—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –∞—Ä—Ö–∏–≤–∞ –∏–∑ MinIO: %w", err)
	}

	return nil
}

func (s *MinIOStorage) GeneratePresignedURL(ctx context.Context, objectName string, expiry time.Duration) (string, error) {
	s.log.InfoContext(ctx, "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–µ—Å–∏–≥–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å—Å—ã–ª–∫–∏ –¥–ª—è –∞—Ä—Ö–∏–≤–∞",
		logger.String("object_name", objectName),
		logger.String("bucket", s.config.DefaultBucket),
		logger.Duration("expiry", expiry))

	origURL, err := s.minioClient.GeneratePresignedURL(ctx, s.config.DefaultBucket, objectName, expiry)
	if err != nil {
		s.log.ErrorContext(ctx, "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–µ—Å–∏–≥–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å—Å—ã–ª–∫–∏",
			logger.String("object_name", objectName),
			logger.Error(err))
		return "", fmt.Errorf("–æ—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–µ—Å–∏–≥–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å—Å—ã–ª–∫–∏: %w", err)
	}

	if s.config.PublicAccessURL != "" {
		publicBase, err := url.Parse(s.config.PublicAccessURL)
		if err == nil {
			parsed := *origURL
			parsed.Scheme = publicBase.Scheme
			parsed.Host = publicBase.Host
			parsed.Path = publicBase.Path + parsed.Path // üí• –∏–º–µ–Ω–Ω–æ —Ç–∞–∫

			s.log.InfoContext(ctx, "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–µ—Å–∏–≥–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å—Å—ã–ª–∫–∏ –¥–ª—è –∞—Ä—Ö–∏–≤–∞",
				logger.String("link", parsed.String()))

			return parsed.String(), nil
		}
	}

	return origURL.String(), nil
}
